{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3acc2b4c-ef76-4dbf-84db-09bcce2d2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing           import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition           import TruncatedSVD\n",
    "from sklearn.linear_model            import SGDClassifier, LogisticRegression\n",
    "from sklearn.calibration             import CalibratedClassifierCV\n",
    "from sklearn.ensemble                import (\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from sklearn.tree                    import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes             import GaussianNB\n",
    "from lightgbm                        import LGBMClassifier\n",
    "from catboost                        import CatBoostClassifier\n",
    "\n",
    "# Load the data\n",
    "train      = pd.read_csv('train.csv')\n",
    "test       = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857d1bc5-3427-4739-b1b3-ad0bc81b7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare text and categorical encodings\n",
    "le_lang = LabelEncoder().fit(pd.concat([train.lang, test.lang]).fillna('NA'))\n",
    "le_loc  = LabelEncoder().fit(pd.concat([train.location, test.location]).fillna('NA'))\n",
    "\n",
    "# TF–IDF vectorizer on descriptions, capped at 1k features\n",
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1,2)).fit(\n",
    "    pd.concat([train.description.fillna(''), test.description.fillna('')])\n",
    ")\n",
    "\n",
    "# SVD to reduce TF–IDF down to 20 components\n",
    "svd = TruncatedSVD(n_components=20, random_state=42)\n",
    "\n",
    "# Precompute frequency counts for freqency encoding\n",
    "lang_freq = train.lang.fillna('NA').value_counts()\n",
    "loc_freq  = train.location.fillna('NA').value_counts()\n",
    "\n",
    "def preprocess(df, fit_svd=False):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Time features\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "    df['acct_weekday'] = df['created_at'].dt.weekday\n",
    "    df['acct_hour']    = df['created_at'].dt.hour\n",
    "\n",
    "    # Log-scale skewed counts\n",
    "    for c in ['followers_count','friends_count','statuses_count','favourites_count']:\n",
    "        df[f'log1p_{c}'] = np.log1p(df[c])\n",
    "\n",
    "    # Activity ratios\n",
    "    df['statuses_per_day']      = df['statuses_count']      / (df['account_age_days'] + 1)\n",
    "    df['favourites_per_day']    = df['favourites_count']     / (df['account_age_days'] + 1)\n",
    "    df['friends_followers_ratio']= df['friends_count']       / (df['followers_count'] + 1)\n",
    "    df['tweets_fav_ratio']      = df['statuses_count']      / (df['favourites_count'] + 1)\n",
    "\n",
    "    # Description text stats\n",
    "    desc = df['description'].fillna('')\n",
    "    df['desc_len']         = desc.str.len()\n",
    "    df['has_desc']         = (df['desc_len'] > 0).astype(int)\n",
    "    df['desc_hashtags']    = desc.str.count(r'#\\w+')\n",
    "    df['desc_mentions']    = desc.str.count(r'@\\w+')\n",
    "    df['desc_urls']        = desc.str.count(r'https?://')\n",
    "    df['desc_upper_ratio'] = desc.str.count(r'[A-Z]') / (df['desc_len'] + 1)\n",
    "    df['desc_digit_ratio'] = desc.str.count(r'\\d')   / (df['desc_len'] + 1)\n",
    "\n",
    "    # Boolean flags\n",
    "    for flag in ['default_profile','default_profile_image','geo_enabled','verified']:\n",
    "        df[flag] = df[flag].astype(int)\n",
    "\n",
    "    # Frequency encoding for low-card columns\n",
    "    df['lang_freq']     = df['lang'].map(lang_freq).fillna(0).astype(int)\n",
    "    df['location_freq'] = df['location'].map(loc_freq).fillna(0).astype(int)\n",
    "\n",
    "    # Label encoding\n",
    "    df['lang_le'] = le_lang.transform(df['lang'].fillna('NA'))\n",
    "    df['loc_le']  = le_loc.transform(df['location'].fillna('NA'))\n",
    "\n",
    "    # TF–IDF\n",
    "    tf_mat = tfidf.transform(desc)\n",
    "    if fit_svd:\n",
    "        svd.fit(tf_mat)\n",
    "    tf_svd = svd.transform(tf_mat)\n",
    "\n",
    "    # Drop raw/text columns not needed\n",
    "    df = df.drop(columns=[\n",
    "        'id','screen_name',\n",
    "        'profile_background_image_url','profile_image_url',\n",
    "        'description','created_at','lang','location'\n",
    "    ], errors='ignore')\n",
    "\n",
    "    return df, tf_mat, tf_svd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e028b919-5b97-4378-8df5-e5d4993a8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess train, test\n",
    "train_df, train_tf, train_svd = preprocess(train, fit_svd=True)\n",
    "test_df,  test_tf,  test_svd  = preprocess(test)\n",
    "\n",
    "y_train = train['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d4fecd-b5f3-4a68-8ada-12c4c13316d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble full feature matrix\n",
    "tf_cols  = [f'tfidf_{i}' for i in range(train_tf.shape[1])]\n",
    "svd_cols = [f'svd_{i}'   for i in range(train_svd.shape[1])]\n",
    "\n",
    "X_train = pd.concat([\n",
    "    train_df.reset_index(drop=True),\n",
    "    pd.DataFrame(train_tf.toarray(), columns=tf_cols),\n",
    "    pd.DataFrame(train_svd,        columns=svd_cols)\n",
    "], axis=1)\n",
    "\n",
    "X_test = pd.concat([\n",
    "    test_df.reset_index(drop=True),\n",
    "    pd.DataFrame(test_tf.toarray(), columns=tf_cols),\n",
    "    pd.DataFrame(test_svd,         columns=svd_cols)\n",
    "], axis=1)\n",
    "\n",
    "# Drop stray index/target columns\n",
    "for df_ in (X_train, X_test):\n",
    "    for c in ('index','target'):\n",
    "        if c in df_.columns:\n",
    "            df_.drop(columns=c, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9652bb0e-2b31-4db2-a002-0a085120beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tuned base learners\n",
    "base_models = {\n",
    "    'sgd': CalibratedClassifierCV(\n",
    "        SGDClassifier(\n",
    "            loss='log_loss',\n",
    "            penalty='elasticnet',\n",
    "            alpha=1e-4,\n",
    "            l1_ratio=0.15,\n",
    "            learning_rate='invscaling',\n",
    "            eta0=0.01,\n",
    "            max_iter=5000,\n",
    "            tol=1e-5,\n",
    "            class_weight='balanced',\n",
    "            random_state=42\n",
    "        ),\n",
    "        cv=3, n_jobs=-1\n",
    "    ),\n",
    "    'hgb': HistGradientBoostingClassifier(\n",
    "        loss='log_loss',\n",
    "        learning_rate=0.02,\n",
    "        max_iter=500,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=20,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'lgb': LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        objective='binary',\n",
    "        metric='auc',\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=800,\n",
    "        num_leaves=31,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=0.5,\n",
    "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    'cat': CatBoostClassifier(\n",
    "        iterations=800,\n",
    "        learning_rate=0.01,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=3,\n",
    "        bagging_temperature=0.5,\n",
    "        border_count=128,\n",
    "        verbose=False,\n",
    "        random_seed=42\n",
    "    ),\n",
    "    'rf': RandomForestClassifier(\n",
    "        n_estimators=800,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'ada': AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1, class_weight='balanced'),\n",
    "        n_estimators=300,\n",
    "        learning_rate=1.0,\n",
    "        algorithm='SAMME.R',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'nb': GaussianNB(var_smoothing=1e-9)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5bbf75-fc7d-4323-9fb5-5c75f362ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a small stacking ensemble\n",
    "stack = StackingClassifier(\n",
    "    estimators=[(name, mdl) for name, mdl in base_models.items()],\n",
    "    final_estimator=LogisticRegression(C=1.0, max_iter=1000),\n",
    "    cv=5, n_jobs=-1, passthrough=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7a6ef1a-9669-4311-9898-83ef5909c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index    target\n",
      "0      0  0.030306\n",
      "1      1  0.875539\n",
      "2      2  0.077401\n",
      "3      3  0.042577\n",
      "4      4  0.967537\n"
     ]
    }
   ],
   "source": [
    "# Train & make predictions\n",
    "stack.fit(X_train, y_train)\n",
    "submission['target'] = stack.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Save to disk\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
